[2023-11-03T18:21:53.232+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: people.create_people_table manual__2023-11-03T18:21:51.259469+00:00 [queued]>
[2023-11-03T18:21:53.251+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: people.create_people_table manual__2023-11-03T18:21:51.259469+00:00 [queued]>
[2023-11-03T18:21:53.252+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2023-11-03T18:21:53.253+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 1
[2023-11-03T18:21:53.254+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2023-11-03T18:21:53.277+0000] {taskinstance.py:1383} INFO - Executing <Task(PostgresOperator): create_people_table> on 2023-11-03 18:21:51.259469+00:00
[2023-11-03T18:21:53.283+0000] {standard_task_runner.py:55} INFO - Started process 902 to run task
[2023-11-03T18:21:53.287+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'people', 'create_people_table', 'manual__2023-11-03T18:21:51.259469+00:00', '--job-id', '108', '--raw', '--subdir', 'DAGS_FOLDER/people.py', '--cfg-path', '/tmp/tmplrt5j9tp']
[2023-11-03T18:21:53.288+0000] {standard_task_runner.py:83} INFO - Job 108: Subtask create_people_table
[2023-11-03T18:21:53.357+0000] {task_command.py:376} INFO - Running <TaskInstance: people.create_people_table manual__2023-11-03T18:21:51.259469+00:00 [running]> on host 6b65bc8eaea5
[2023-11-03T18:21:53.442+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=people
AIRFLOW_CTX_TASK_ID=create_people_table
AIRFLOW_CTX_EXECUTION_DATE=2023-11-03T18:21:51.259469+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-11-03T18:21:51.259469+00:00
[2023-11-03T18:21:53.454+0000] {base.py:71} INFO - Using connection ID 'postgres_people' for task execution.
[2023-11-03T18:21:53.459+0000] {sql.py:315} INFO - Running statement: 
        CREATE TABLE IF NOT EXISTS test.people (
            Index INT NOT NULL primary key,
            User_Id varchar(100),
            First_Name varchar(100),
            Last_Name varchar(100),
            Sex varchar(100),
            Email varchar(100)
        );
    , parameters: None
[2023-11-03T18:21:53.460+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 94, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 295, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 320, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.InvalidSchemaName: schema "test" does not exist
LINE 2:         CREATE TABLE IF NOT EXISTS test.people (
                                           ^

[2023-11-03T18:21:53.470+0000] {taskinstance.py:1406} INFO - Marking task as FAILED. dag_id=people, task_id=create_people_table, execution_date=20231103T182151, start_date=20231103T182153, end_date=20231103T182153
[2023-11-03T18:21:53.484+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 108 for task create_people_table (schema "test" does not exist
LINE 2:         CREATE TABLE IF NOT EXISTS test.people (
                                           ^
; 902)
[2023-11-03T18:21:53.499+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2023-11-03T18:21:53.534+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
