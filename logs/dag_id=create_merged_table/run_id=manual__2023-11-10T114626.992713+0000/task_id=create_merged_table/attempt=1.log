[2023-11-10T11:46:28.942+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: create_merged_table.create_merged_table manual__2023-11-10T11:46:26.992713+00:00 [queued]>
[2023-11-10T11:46:28.959+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: create_merged_table.create_merged_table manual__2023-11-10T11:46:26.992713+00:00 [queued]>
[2023-11-10T11:46:28.962+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-11-10T11:46:28.963+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 1
[2023-11-10T11:46:28.964+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-11-10T11:46:28.986+0000] {taskinstance.py:1304} INFO - Executing <Task(PostgresOperator): create_merged_table> on 2023-11-10 11:46:26.992713+00:00
[2023-11-10T11:46:28.992+0000] {standard_task_runner.py:55} INFO - Started process 793 to run task
[2023-11-10T11:46:28.997+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'create_merged_table', 'create_merged_table', 'manual__2023-11-10T11:46:26.992713+00:00', '--job-id', '503', '--raw', '--subdir', 'DAGS_FOLDER/union.py', '--cfg-path', '/tmp/tmpjf1_kjmo']
[2023-11-10T11:46:29.000+0000] {standard_task_runner.py:83} INFO - Job 503: Subtask create_merged_table
[2023-11-10T11:46:29.168+0000] {task_command.py:389} INFO - Running <TaskInstance: create_merged_table.create_merged_table manual__2023-11-10T11:46:26.992713+00:00 [running]> on host ae05fe974d8d
[2023-11-10T11:46:29.307+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Tetiana
AIRFLOW_CTX_DAG_ID=create_merged_table
AIRFLOW_CTX_TASK_ID=create_merged_table
AIRFLOW_CTX_EXECUTION_DATE=2023-11-10T11:46:26.992713+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-11-10T11:46:26.992713+00:00
[2023-11-10T11:46:29.309+0000] {sql.py:253} INFO - Executing: 
        CREATE TABLE IF NOT EXISTS merged_table AS
        SELECT
        people.user_id AS people_user_id,
        people.first_name AS people_first_name,
        people.last_name AS people_last_name,
        people.sex AS people_sex,
        people.email AS people_email,
        people.phone AS people_phone,
        people.date_of_birth AS people_date_of_birth,
        people.job_title AS people_job_title
        FROM people, customers
        LEFT JOIN people ON people.user_id = customers.customer_id;
        
[2023-11-10T11:46:29.320+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-11-10T11:46:29.616+0000] {base.py:73} INFO - Using connection ID 'postgres' for task execution.
[2023-11-10T11:46:29.621+0000] {sql.py:364} INFO - Running statement: 
        CREATE TABLE IF NOT EXISTS merged_table AS
        SELECT
        people.user_id AS people_user_id,
        people.first_name AS people_first_name,
        people.last_name AS people_last_name,
        people.sex AS people_sex,
        people.email AS people_email,
        people.phone AS people_phone,
        people.date_of_birth AS people_date_of_birth,
        people.job_title AS people_job_title
        FROM people, customers
        LEFT JOIN people ON people.user_id = customers.customer_id;
        , parameters: None
[2023-11-10T11:46:29.625+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 261, in execute
    return_last=self.return_last,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 338, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/hooks/sql.py", line 369, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.DuplicateAlias: table name "people" specified more than once

[2023-11-10T11:46:29.637+0000] {taskinstance.py:1327} INFO - Marking task as FAILED. dag_id=create_merged_table, task_id=create_merged_table, execution_date=20231110T114626, start_date=20231110T114628, end_date=20231110T114629
[2023-11-10T11:46:29.656+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 503 for task create_merged_table (table name "people" specified more than once
; 793)
[2023-11-10T11:46:29.703+0000] {local_task_job.py:159} INFO - Task exited with return code 1
[2023-11-10T11:46:29.726+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
